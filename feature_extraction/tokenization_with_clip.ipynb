{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Load libraries\n",
        "\n",
        "* load tokenizer from [CLIP](https://github.com/openai/CLIP)"
      ],
      "metadata": {
        "id": "Z7RA1iZQcqJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAH9VV2DaecC",
        "outputId": "e297e953-3aaf-4727-f49c-2fb8d57908ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-mlnd6r1l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-mlnd6r1l\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (0.14.1+cu116)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->clip==1.0) (0.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "from clip import simple_tokenizer"
      ],
      "metadata": {
        "id": "rvRtzcZPY-Ju"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze tokenization"
      ],
      "metadata": {
        "id": "C_GLEwJIc0c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize tokenizer\n",
        "tokenizer = simple_tokenizer.SimpleTokenizer()\n",
        "\n",
        "# set test samples\n",
        "samples = [\n",
        "    'text in Arabic',\n",
        "    'word in Russian',\n",
        "    'caption in English'\n",
        "]\n",
        "\n",
        "# observe encoding for the samples\n",
        "for sample in samples:\n",
        "\n",
        "  print('SAMPLE: ', sample)\n",
        "\n",
        "  bpe = tokenizer.bpe(sample)\n",
        "  print('BPE:    ', bpe)\n",
        "\n",
        "  encoded = tokenizer.encode(bpe)\n",
        "  print('ENDODED:', encoded)\n",
        "\n",
        "  print('DECODED:', tokenizer.decode(encoded))\n",
        "  print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqfFRx6gbPXX",
        "outputId": "864b244a-394d-4b96-e975-b0b96ed06a1e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE:  text in Arabic\n",
            "BPE:     text   in   A ra bic</w>\n",
            "ENDODED: [4160, 530, 320, 1735, 10675, 34308, 342, 285]\n",
            "DECODED: text in a ra bic </ w > \n",
            "\n",
            "SAMPLE:  word in Russian\n",
            "BPE:     word   in   R u ssian</w>\n",
            "ENDODED: [2653, 530, 337, 340, 31218, 34308, 342, 285]\n",
            "DECODED: word in r u ssian </ w > \n",
            "\n",
            "SAMPLE:  caption in English\n",
            "BPE:     cap tion   in   E ng lish</w>\n",
            "ENDODED: [3938, 740, 530, 324, 5215, 2354, 34308, 342, 285]\n",
            "DECODED: cap tion in e ng lish </ w > \n",
            "\n"
          ]
        }
      ]
    }
  ]
}